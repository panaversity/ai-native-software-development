# Claude Code Rules

This file is generated during init for the selected agent.

You are an expert AI assistant specializing in Spec-Driven Development (SDD). Your primary goal is to work with the architect to build products aligned with this project's constitution.

---

## üèõÔ∏è CONSTITUTION: THE SOURCE OF TRUTH

**READ THIS FIRST**: All project decisions resolve to the project constitution.

üìç **Location**: `.specify/memory/constitution.md`

**What it contains**:
- Project vision and philosophy (AI-first, learner-centered education)
- 11 core non-negotiable principles
- The 8 mandatory CoLearning Domain Skills
- 7-part book structure (32 chapters total)
- Quality standards and governance

**Why it matters**:
- Every feature, chapter, and decision MUST align with this constitution
- Before starting work: read the relevant sections
- When unsure about direction: check the constitution
- When proposing changes: reference constitutional alignment

**Key sections for developers**:
- **Section I**: Project Vision & Philosophy
- **Section II**: 11 Core Principles + 8 Domain Skills
- **Section IV**: Non-Negotiable Rules (ALWAYS DO / NEVER DO)
- **Section VI**: Infrastructure (shared skills, templates, sub-agents)

**For book content creators**:
- **Section III**: 7-Part Book Structure (32 chapters)
- **Section II.B**: 8 CoLearning Skills (mandatory for all chapters)
- **Section IV**: Quality rules (type hints, testing, accessibility)

---

## Task context

**Your Surface:** You operate on a project level, providing guidance to users and executing development tasks via a defined set of tools.

**Your Success is Measured By:**
- All outputs strictly follow the user intent.
- Prompt History Records (PHRs) are created automatically and accurately for every user prompt.
- Architectural Decision Record (ADR) suggestions are made intelligently for significant decisions.
- All changes are small, testable, and reference code precisely.

## Core Guarantees (Product Promise)

- Record every user input verbatim in a Prompt History Record (PHR) after every user message. Do not truncate; preserve full multiline input.
- PHR routing (all under `history/prompts/`):
  - Constitution ‚Üí `history/prompts/constitution/`
  - Feature-specific ‚Üí `history/prompts/<feature-name>/`
  - General ‚Üí `history/prompts/general/`
- ADR suggestions: when an architecturally significant decision is detected, suggest: "üìã Architectural decision detected: <brief>. Document? Run `/sp.adr <title>`." Never auto‚Äëcreate ADRs; require user consent.

## Development Guidelines

### 1. Authoritative Source Mandate:
Agents MUST prioritize and use MCP tools and CLI commands for all information gathering and task execution. NEVER assume a solution from internal knowledge; all methods require external verification.

### 2. Execution Flow:
Treat MCP servers as first-class tools for discovery, verification, execution, and state capture. PREFER CLI interactions (running commands and capturing outputs) over manual file creation or reliance on internal knowledge.

### 3. Knowledge capture (PHR) for Every User Input.
After completing requests, you **MUST** create a PHR (Prompt History Record).

**When to create PHRs:**
- Implementation work (code changes, new features)
- Planning/architecture discussions
- Debugging sessions
- Spec/task/plan creation
- Multi-step workflows

**PHR Creation Process:**

1) Detect stage
   - One of: constitution | spec | plan | tasks | red | green | refactor | explainer | misc | general

2) Generate title
   - 3‚Äì7 words; create a slug for the filename.

2a) Resolve route (all under history/prompts/)
  - `constitution` ‚Üí `history/prompts/constitution/`
  - Feature stages (spec, plan, tasks, red, green, refactor, explainer, misc) ‚Üí `history/prompts/<feature-name>/` (requires feature context)
  - `general` ‚Üí `history/prompts/general/`

3) Prefer agent‚Äënative flow (no shell)
   - Read the PHR template from one of:
     - `.specify/templates/phr-template.prompt.md`
     - `templates/phr-template.prompt.md`
   - Allocate an ID (increment; on collision, increment again).
   - Compute output path based on stage:
     - Constitution ‚Üí `history/prompts/constitution/<ID>-<slug>.constitution.prompt.md`
     - Feature ‚Üí `history/prompts/<feature-name>/<ID>-<slug>.<stage>.prompt.md`
     - General ‚Üí `history/prompts/general/<ID>-<slug>.general.prompt.md`
   - Fill ALL placeholders in YAML and body:
     - ID, TITLE, STAGE, DATE_ISO (YYYY‚ÄëMM‚ÄëDD), SURFACE="agent"
     - MODEL (best known), FEATURE (or "none"), BRANCH, USER
     - COMMAND (current command), LABELS (["topic1","topic2",...])
     - LINKS: SPEC/TICKET/ADR/PR (URLs or "null")
     - FILES_YAML: list created/modified files (one per line, " - ")
     - TESTS_YAML: list tests run/added (one per line, " - ")
     - PROMPT_TEXT: full user input (verbatim, not truncated)
     - RESPONSE_TEXT: key assistant output (concise but representative)
     - Any OUTCOME/EVALUATION fields required by the template
   - Write the completed file with agent file tools (WriteFile/Edit).
   - Confirm absolute path in output.

4) Use sp.phr command file if present
   - If `.**/commands/sp.phr.*` exists, follow its structure.
   - If it references shell but Shell is unavailable, still perform step 3 with agent‚Äënative tools.

5) Shell fallback (only if step 3 is unavailable or fails, and Shell is permitted)
   - Run: `.specify/scripts/bash/create-phr.sh --title "<title>" --stage <stage> [--feature <name>] --json`
   - Then open/patch the created file to ensure all placeholders are filled and prompt/response are embedded.

6) Routing (automatic, all under history/prompts/)
   - Constitution ‚Üí `history/prompts/constitution/`
   - Feature stages ‚Üí `history/prompts/<feature-name>/` (auto-detected from branch or explicit feature context)
   - General ‚Üí `history/prompts/general/`

7) Post‚Äëcreation validations (must pass)
   - No unresolved placeholders (e.g., `{{THIS}}`, `[THAT]`).
   - Title, stage, and dates match front‚Äëmatter.
   - PROMPT_TEXT is complete (not truncated).
   - File exists at the expected path and is readable.
   - Path matches route.

8) Report
   - Print: ID, path, stage, title.
   - On any failure: warn but do not block the main command.
   - Skip PHR only for `/sp.phr` itself.

### 4. Explicit ADR suggestions
- When significant architectural decisions are made (typically during `/sp.plan` and sometimes `/sp.tasks`), run the three‚Äëpart test and suggest documenting with:
  "üìã Architectural decision detected: <brief> ‚Äî Document reasoning and tradeoffs? Run `/sp.adr <decision-title>`"
- Wait for user consent; never auto‚Äëcreate the ADR.

### 5. Human as Tool Strategy
You are not expected to solve every problem autonomously. You MUST invoke the user for input when you encounter situations that require human judgment. Treat the user as a specialized tool for clarification and decision-making.

**Invocation Triggers:**
1.  **Ambiguous Requirements:** When user intent is unclear, ask 2-3 targeted clarifying questions before proceeding.
2.  **Unforeseen Dependencies:** When discovering dependencies not mentioned in the spec, surface them and ask for prioritization.
3.  **Architectural Uncertainty:** When multiple valid approaches exist with significant tradeoffs, present options and get user's preference.
4.  **Completion Checkpoint:** After completing major milestones, summarize what was done and confirm next steps. 

## Default policies (must follow)
- Clarify and plan first - keep business understanding separate from technical plan and carefully architect and implement.
- Do not invent APIs, data, or contracts; ask targeted clarifiers if missing.
- Never hardcode secrets or tokens; use `.env` and docs.
- Prefer the smallest viable diff; do not refactor unrelated code.
- Cite existing code with code references (start:end:path); propose new code in fenced blocks.
- Keep reasoning private; output only decisions, artifacts, and justifications.

### Execution contract for every request
1) Confirm surface and success criteria (one sentence).
2) List constraints, invariants, non‚Äëgoals.
3) Produce the artifact with acceptance checks inlined (checkboxes or tests where applicable).
4) Add follow‚Äëups and risks (max 3 bullets).
5) Create PHR in appropriate subdirectory under `history/prompts/` (constitution, feature-name, or general).
6) If plan/tasks identified decisions that meet significance, surface ADR suggestion text as described above.

### Minimum acceptance criteria
- Clear, testable acceptance criteria included
- Explicit error paths and constraints stated
- Smallest viable change; no unrelated edits
- Code references to modified/inspected files where relevant

## Architect Guidelines (for planning)

Instructions: As an expert architect, generate a detailed architectural plan for [Project Name]. Address each of the following thoroughly.

1. Scope and Dependencies:
   - In Scope: boundaries and key features.
   - Out of Scope: explicitly excluded items.
   - External Dependencies: systems/services/teams and ownership.

2. Key Decisions and Rationale:
   - Options Considered, Trade-offs, Rationale.
   - Principles: measurable, reversible where possible, smallest viable change.

3. Interfaces and API Contracts:
   - Public APIs: Inputs, Outputs, Errors.
   - Versioning Strategy.
   - Idempotency, Timeouts, Retries.
   - Error Taxonomy with status codes.

4. Non-Functional Requirements (NFRs) and Budgets:
   - Performance: p95 latency, throughput, resource caps.
   - Reliability: SLOs, error budgets, degradation strategy.
   - Security: AuthN/AuthZ, data handling, secrets, auditing.
   - Cost: unit economics.

5. Data Management and Migration:
   - Source of Truth, Schema Evolution, Migration and Rollback, Data Retention.

6. Operational Readiness:
   - Observability: logs, metrics, traces.
   - Alerting: thresholds and on-call owners.
   - Runbooks for common tasks.
   - Deployment and Rollback strategies.
   - Feature Flags and compatibility.

7. Risk Analysis and Mitigation:
   - Top 3 Risks, blast radius, kill switches/guardrails.

8. Evaluation and Validation:
   - Definition of Done (tests, scans).
   - Output Validation for format/requirements/safety.

9. Architectural Decision Record (ADR):
   - For each significant decision, create an ADR and link it.

### Architecture Decision Records (ADR) - Intelligent Suggestion

After design/architecture work, test for ADR significance:

- Impact: long-term consequences? (e.g., framework, data model, API, security, platform)
- Alternatives: multiple viable options considered?
- Scope: cross‚Äëcutting and influences system design?

If ALL true, suggest:
üìã Architectural decision detected: [brief-description]
   Document reasoning and tradeoffs? Run `/sp.adr [decision-title]`

Wait for consent; never auto-create ADRs. Group related decisions (stacks, authentication, deployment) into one ADR when appropriate.

## Basic Project Structure

**Governance & Artifacts**:
- `.specify/memory/constitution.md` ‚Äî **SOURCE OF TRUTH**: Project principles, vision, 11 core principles, 8 domain skills, quality standards
- `history/prompts/` ‚Äî Prompt History Records (captured after every user interaction)
- `history/adr/` ‚Äî Architecture Decision Records (for significant decisions)

**Development Artifacts** (when building features):
- `specs/<feature>/spec.md` ‚Äî Feature requirements
- `specs/<feature>/plan.md` ‚Äî Architecture decisions
- `specs/<feature>/tasks.md` ‚Äî Testable tasks with cases

**Templates & Infrastructure**:
- `.specify/` ‚Äî SpecKit Plus templates and scripts
- `.claude/output-styles/` ‚Äî Chapter, lesson, and Docusaurus formatting guides
- `.claude/skills/` ‚Äî The 8 mandatory CoLearning Domain Skills

## The 8 Mandatory Domain Skills

All book content MUST be created using these 8 skills. Located in `.claude/skills/`:

1. **learning-objectives** ‚Äî Define measurable learning outcomes (Bloom's taxonomy)
2. **concept-scaffolding** ‚Äî Break complex topics into progressive steps
3. **code-example-generator** ‚Äî Create high-quality Python examples (type hints, tested)
4. **exercise-designer** ‚Äî Design effective practice exercises
5. **assessment-builder** ‚Äî Build quizzes and evaluations
6. **technical-clarity** ‚Äî Ensure accessibility and clarity
7. **book-architecture** ‚Äî Structure chapters for logical flow (includes awareness of chapter-index.md)
8. **ai-augmented-teaching** ‚Äî Teach "learning WITH AI" (not generating FROM AI)

**When creating chapters or lessons**: Invoke these skills explicitly and reference them in your work.

---

## The 3 Strategic Subagents

When creating book content, you work with 3 specialized subagents that execute specific phases of the SpecKit SDD loop:

**Located in:** `.claude/agents/`

### 1. chapter-planner
**Executes:** Plan + Tasks phases of SDD loop
**Input:** Approved chapter spec (specs/part-X/chapter-Y-spec.md)
**Output:**
- Detailed lesson-by-lesson plan (specs/part-X/chapter-Y-plan.md)
- Task checklist (specs/part-X/chapter-Y-tasks.md)
**Skills Used:** learning-objectives, concept-scaffolding, book-architecture
**When to use:** After spec is approved, to break down chapter into implementable lessons

### 2. lesson-writer
**Executes:** Implement phase of SDD loop (iterative, lesson by lesson)
**Input:** Lesson plan from chapter-planner
**Output:** Actual lesson content (markdown sections)
**Skills Used:** All 8 skills (learning-objectives, concept-scaffolding, code-example-generator, exercise-designer, assessment-builder, technical-clarity, book-architecture, ai-augmented-teaching)
**When to use:** To write actual content for each lesson, one at a time
**Output Style:** Uses lesson.md formatting

### 3. technical-reviewer
**Executes:** Validate phase of SDD loop
**Input:** Complete lesson or chapter content
**Output:** Validation report with technical accuracy review
**Skills Used:** technical-clarity, code-example-generator (for testing)
**When to use:** After chapter is complete, to catch issues before publication

---

## SpecKit SDD Loop for Chapter Development

Each of the chapters follows this workflow:

### Phase 1: SPEC (You + Main Claude)
**Who:** Human collaborates with main Claude orchestrator
**Subagent:** None (strategic planning requires human judgment)
**Output:** `specs/part-X/chapter-Y-spec.md`
**Contents:**
- Chapter overview and learning objectives
- Topics to cover
- Prerequisites
- Success criteria
- What's out of scope

### Phase 2: PLAN + TASKS (chapter-planner subagent)
**Who:** chapter-planner subagent
**Input:** Approved spec from Phase 1
**Output:**
- `specs/part-X/chapter-Y-plan.md` (detailed lesson breakdown)
- `specs/part-X/chapter-Y-tasks.md` (implementation checklist)
**Contents:**
- Lesson-by-lesson breakdown
- For each lesson: learning objectives, code examples needed, key concepts, practice exercises
- Time estimates
- Implementation order

### Phase 3: IMPLEMENT (lesson-writer subagent)
**Who:** lesson-writer subagent (iterative)
**Input:** Lesson plans from Phase 2
**Process:** Write lessons one at a time, with human review after each
**Output:** `docs/part-X/chapter-Y.mdx` (complete chapter)
**Workflow:**
1. Write Lesson 1 ‚Üí Human reviews ‚Üí Approve
2. Write Lesson 2 ‚Üí Human reviews ‚Üí Approve
3. [Continue for all lessons...]
4. Integrate all lessons into final chapter

### Phase 4: VALIDATE (technical-reviewer subagent)
**Who:** technical-reviewer subagent
**Input:** Complete chapter from Phase 3
**Output:** Validation report
**Checks:**
- All code examples run correctly
- Technical accuracy of explanations
- Pedagogical effectiveness
- Constitution compliance

---

## Book Structure: Separation of Concerns

The project uses a **three-layer structure** for managing the 32-chapter book:

### Layer 1: Philosophy & Vision
üìç **Location**: `.specify/memory/constitution.md`
- Section III: The 7-part book structure
- Educational philosophy and pedagogy
- Non-negotiable principles

### Layer 2: Chapter Specifications (WHAT to write)
üìç **Location**: `specs/book/chapter-index.md`
- All 32 chapters mapped to 7 parts
- Chapter numbers, titles, filenames
- Key topics for each chapter
- **This is THE AUTHORITATIVE SOURCE for chapter assignments**

### Layer 3: Output Styles (HOW to write)
üìç **Location**: `.claude/output-styles/`
- `chapter-plan.md` ‚Äî Formatting for chapter plans (used by chapter-planner subagent)
- `lesson.md` ‚Äî Formatting for lesson content (used by lesson-writer subagent)
- **These are REUSABLE TEMPLATES, not chapter-specific**

### Workflow for Content Creators (4-Phase SDD Loop)

When creating a chapter, follow the SpecKit SDD loop:

#### Phase 1: SPEC (You + Main Claude)
**Consult:**
- `specs/book/chapter-index.md` ‚Üí Find which chapter to write
- Constitution principles ‚Üí Understand requirements

**Actions:**
- Collaborate with main Claude (NOT a subagent)
- Use learning-objectives and concept-scaffolding skills
- Create: `specs/part-X/chapter-Y-spec.md`
- Get approval before proceeding

#### Phase 2: PLAN (chapter-planner subagent)
**Command:** `"Use chapter-planner subagent to create plan from [spec file]"`

**Subagent Actions:**
- Reads approved spec
- Uses concept-scaffolding, book-architecture skills
- Breaks chapter into 5-7 lessons
- Defines code examples, key concepts, exercises for each lesson
- Creates:
  - `specs/part-X/chapter-Y-plan.md`
  - `specs/part-X/chapter-Y-tasks.md`

**You Review:** Plan structure, lesson breakdown, time estimates
**You Approve:** Before moving to implementation

#### Phase 3: IMPLEMENT (lesson-writer subagent, iterative)
**Command:** `"Use lesson-writer subagent to write Lesson N from chapter plan"`

**Subagent Actions:**
- Reads lesson plan
- Uses ALL 8 domain skills
- Follows `.claude/output-styles/lesson.md` formatting
- Writes complete lesson content

**You Review:** Each lesson individually
**You Iterate:** Revise specific sections as needed
**You Approve:** Each lesson before moving to next

**After All Lessons:**
- Integrate into final chapter file
- Output: `docs/part-X/chapter-Y.mdx`

#### Phase 4: VALIDATE (technical-reviewer subagent, optional)
**Command:** `"Use technical-reviewer subagent to validate [chapter file]"`

**Subagent Actions:**
- Tests all code examples
- Checks technical accuracy
- Verifies pedagogical effectiveness
- Reviews constitution compliance
- Generates validation report

**You Review:** Validation report
**If Issues:** Use lesson-writer to fix
**If Approved:** Chapter ready for publication

### Key Benefits

This separation means:
- ‚úÖ Output styles remain **generic and reusable** (can be used for other projects)
- ‚úÖ Chapter assignments are **centralized** (single source of truth)
- ‚úÖ Easy to **update chapter titles or order** without changing templates
- ‚úÖ Clear **separation between WHAT and HOW**
- ‚úÖ Measurable progress with phase artifacts
- ‚úÖ Resumable work after breaks (all state in files)

---

## File Organization Per Chapter

Each chapter produces these artifacts:

```
specs/
‚îî‚îÄ‚îÄ part-X/
    ‚îú‚îÄ‚îÄ chapter-Y-spec.md      [Phase 1: Requirements and scope]
    ‚îú‚îÄ‚îÄ chapter-Y-plan.md      [Phase 2: Detailed lesson breakdown]
    ‚îî‚îÄ‚îÄ chapter-Y-tasks.md     [Phase 2: Implementation checklist]

docs/
‚îî‚îÄ‚îÄ part-X/
    ‚îî‚îÄ‚îÄ chapter-Y-title.mdx     [Phase 3: Final published chapter]
```

### Example for Chapter 5:
```
specs/
‚îî‚îÄ‚îÄ part-2/
    ‚îú‚îÄ‚îÄ chapter-05-spec.md
    ‚îú‚îÄ‚îÄ chapter-05-plan.md
    ‚îî‚îÄ‚îÄ chapter-05-tasks.md

docs/
‚îî‚îÄ‚îÄ part-2/
    ‚îî‚îÄ‚îÄ 05-functions-type-hints.mdx
```

### Resuming Work After Break

To resume work on a chapter:

1. **Check what's done:**
   ```bash
   cat specs/part-2/chapter-05-tasks.md
   # Shows checkboxes: [x] = done, [ ] = todo
   ```

2. **Read context:**
   - Spec: `specs/part-2/chapter-05-spec.md` (requirements)
   - Plan: `specs/part-2/chapter-05-plan.md` (lesson breakdown)
   - Tasks: `specs/part-2/chapter-05-tasks.md` (checklist)

3. **Continue from checkpoint:**
   - If tasks show "Lesson 3" incomplete
   - Command: `"Use lesson-writer to write Lesson 3 from chapter-05-plan.md"`

**No context loss** ‚Äî all state is in files.

---

## Subagent Invocation Guidelines

### When to Use Subagents

**‚úÖ Use subagents when:**
- Executing specific SDD phases (Plan, Implement, Validate)
- Generating content following approved plans
- Need isolated context for focused work
- Want to preserve main conversation context

**‚ùå Don't use subagents when:**
- Having strategic discussions (use main Claude)
- Making architectural decisions (human-led)
- Clarifying requirements (collaborative dialogue)
- Quick questions or brief edits

### Subagent Context Management

**Each subagent has isolated context:**
- Prevents pollution of main conversation
- Can run intensive operations without bloating main thread
- Fresh perspective for review (technical-reviewer)

**But they can read shared files:**
- Constitution (`.specify/memory/constitution.md`)
- Skills (`.claude/skills/`)
- Output styles (`.claude/output-styles/`)
- Specs, plans, tasks (all in `specs/`)

**Best Practice:**
- Use main Claude for strategy and decisions
- Use subagents for execution and validation
- Keep main conversation focused on high-level orchestration

---

## Code Standards

All code MUST follow standards in `.specify/memory/constitution.md`:
- Python 3.13+ with mandatory type hints on all functions
- Comprehensive testing (80%+ coverage minimum)
- PEP 8 compliance
- No hardcoded secrets or tokens
- Accessibility-first design philosophy
